
@article{altmannIncrementalInterpretationVerbs1999,
  title = {Incremental Interpretation at Verbs: Restricting the Domain of Subsequent Reference},
  shorttitle = {Incremental Interpretation at Verbs},
  author = {Altmann, Gerry T.M and Kamide, Yuki},
  year = {1999},
  month = dec,
  volume = {73},
  pages = {247--264},
  issn = {00100277},
  doi = {10.1016/S0010-0277(99)00059-1},
  abstract = {Participants' eye movements were recorded as they inspected a semi-realistic visual scene showing a boy, a cake, and various distractor objects. Whilst viewing this scene, they heard sentences such as `the boy will move the cake' or `the boy will eat the cake'. The cake was the only edible object portrayed in the scene. In each of two experiments, the onset of saccadic eye movements to the target object (the cake) was signi\textregistered cantly later in the move condition than in the eat condition; saccades to the target were launched after the onset of the spoken word cake in the move condition, but before its onset in the eat condition. The results suggest that information at the verb can be used to restrict the domain within the context to which subsequent reference will be made by the (as yet unencountered) post-verbal grammatical object. The data support a hypothesis in which sentence processing is driven by the predictive relationships between verbs, their syntactic arguments, and the real-world contexts in which they occur. q 1999 Elsevier Science B.V. All rights reserved.},
  journal = {Cognition},
  keywords = {eye-tracking,language comprehension,prediction,semantics,syntax},
  language = {en},
  number = {3}
}

@article{anwyl2020gorilla,
  title={Gorilla in our midst: An online behavioral experiment builder},
  author={Anwyl-Irvine, Alexander L and Massonni{\'e}, Jessica and Flitton, Adam and Kirkham, Natasha and Evershed, Jo K},
  journal={Behavior research methods},
  volume={52},
  pages={388--407},
  year={2020},
  publisher={Springer}
}
@article{banki2022comparing,
  title={Comparing online webcam-and laboratory-based eye-tracking for the assessment of infants’ audio-visual synchrony perception},
  author={B{\'a}nki, Anna and de Eccher, Martina and Falschlehner, Lilith and Hoehl, Stefanie and Markova, Gabriela},
  journal={Frontiers in Psychology},
  volume={12},
  pages={733933},
  year={2022},
  publisher={Frontiers}
}
@inproceedings{degen2021seeing,
  title={Seeing is believing: Testing an explicit linking assumption for visual world eye-tracking in psycholinguistics},
  author={Degen, Judith and Kursat, Leyla and Leigh, Daisy Dorothy},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={43},
  number={43},
  year={2021}
}
@Article{deleeuwJsPsychJavaScriptLibrary2015,
  title = {{{jsPsych}}: {{A JavaScript}} Library for Creating Behavioral Experiments in a {{Web}} Browser},
  shorttitle = {{{jsPsych}}},
  author = {Joshua R. {de Leeuw}},
  date = {2015-03-01},
  journaltitle = {Behavior Research Methods},
  shortjournal = {Behav Res},
  volume = {47},
  pages = {1--12},
  issn = {1554-3528},
  doi = {10.3758/s13428-014-0458-y},
  abstract = {Online experiments are growing in popularity, and the increasing sophistication of Web technology has made it possible to run complex behavioral experiments online using only a Web browser. Unlike with offline laboratory experiments, however, few tools exist to aid in the development of browser-based experiments. This makes the process of creating an experiment slow and challenging, particularly for researchers who lack a Web development background. This article introduces jsPsych, a JavaScript library for the development of Web-based experiments. jsPsych formalizes a way of describing experiments that is much simpler than writing the entire experiment from scratch. jsPsych then executes these descriptions automatically, handling the flow from one task to another. The jsPsych library is open-source and designed to be expanded by the research community. The project is available online at www.jspsych.org.},
  file = {/Users/rachelryskin/Zotero/storage/U5J3EEUM/de Leeuw - 2015 - jsPsych A JavaScript library for creating behavio.pdf},
  langid = {english},
  number = {1},
  options = {useprefix=true},
}

@article{dijkgraaf2017predicting,
  title={Predicting upcoming information in native-language and non-native-language auditory word recognition},
  author={Dijkgraaf, Aster and Hartsuiker, Robert J and Duyck, Wouter},
  journal={Bilingualism: Language and Cognition},
  volume={20},
  number={5},
  pages={917--930},
  year={2017},
  publisher={Cambridge University Press}
}

@article{gosling2010wired,
  title={Wired but not WEIRD: The promise of the Internet in reaching more diverse samples},
  author={Gosling, Samuel D and Sandy, Carson J and John, Oliver P and Potter, Jeff},
  journal={Behavioral and Brain Sciences},
  volume={33},
  number={2-3},
  pages={94},
  year={2010},
  publisher={Cambridge University Press}
}
@article{snedeker2003using,
  title={Using prosody to avoid ambiguity: Effects of speaker awareness and referential context},
  author={Snedeker, Jesse and Trueswell, John},
  journal={Journal of Memory and language},
  volume={48},
  number={1},
  pages={103--130},
  year={2003},
  publisher={Elsevier}
}
@inproceedings{reinecke2015labinthewild,
  title={LabintheWild: Conducting large-scale online experiments with uncompensated samples},
  author={Reinecke, Katharina and Gajos, Krzysztof Z},
  booktitle={Proceedings of the 18th ACM conference on computer supported cooperative work \& social computing},
  pages={1364--1378},
  year={2015}
}
@inproceedings{skovsgaard2011evaluation,
  title={Evaluation of a remote webcam-based eye tracker},
  author={Skovsgaard, Henrik and Agustin, Javier San and Johansen, Sune Alstrup and Hansen, John Paulin and Tall, Martin},
  booktitle={Proceedings of the 1st conference on novel gaze-controlled applications},
  pages={1--4},
  year={2011}
}
@inproceedings{zheng2018rapid,
  title={A rapid webcam-based eye tracking method for human computer interaction},
  author={Zheng, Chenyang and Usagawa, Tsuyoshi},
  booktitle={2018 International Conference on Control, Automation and Information Sciences (ICCAIS)},
  pages={133--136},
  year={2018},
  organization={IEEE}
}
@inproceedings{burton2014comparison,
  title={A comparison of the performance of webcam vs. infrared eye tracking technology},
  author={Burton, Liz and Albert, William and Flynn, Mark},
  booktitle={Proceedings of the human factors and ergonomics society annual meeting},
  volume={58},
  number={1},
  pages={1437--1441},
  year={2014},
  organization={SAGE Publications Sage CA: Los Angeles, CA}
}
@article{hartshorne2019thousand,
  title={A thousand studies for the price of one: Accelerating psychological science with Pushkin},
  author={Hartshorne, Joshua K and de Leeuw, Joshua R and Goodman, Noah D and Jennings, Mariela and O’Donnell, Timothy J},
  journal={Behavior research methods},
  volume={51},
  pages={1782--1803},
  year={2019},
  publisher={Springer}
}
@article{nosek2022replicability,
  title={Replicability, robustness, and reproducibility in psychological science},
  author={Nosek, Brian A and Hardwicke, Tom E and Moshontz, Hannah and Allard, Aur{\'e}lien and Corker, Katherine S and Dreber, Anna and Fidler, Fiona and Hilgard, Joe and Kline Struhl, Melissa and Nuijten, Mich{\`e}le B and others},
  journal={Annual review of psychology},
  volume={73},
  pages={719--748},
  year={2022},
  publisher={Annual Reviews}
}
@article{li2024developmental,
  title={Developmental psychologists should adopt citizen science to improve generalization and reproducibility},
  author={Li, Wei and Germine, Laura Thi and Mehr, Samuel A and Srinivasan, Mahesh and Hartshorne, Joshua},
  journal={Infant and Child Development},
  volume={33},
  number={1},
  pages={e2348},
  year={2024},
  publisher={Wiley Online Library}
}

@article{hayhoe2005eye,
  title={Eye movements in natural behavior},
  author={Hayhoe, Mary and Ballard, Dana},
  journal={Trends in cognitive sciences},
  volume={9},
  number={4},
  pages={188--194},
  year={2005},
  publisher={Elsevier}
}
@article{henderson2017meaning,
  title={Meaning-based guidance of attention in scenes as revealed by meaning maps},
  author={Henderson, John M and Hayes, Taylor R},
  journal={Nature human behaviour},
  volume={1},
  number={10},
  pages={743--747},
  year={2017},
  publisher={Nature Publishing Group UK London}
}
@article{henninger2021lab,
  title={lab. js: A free, open, online study builder},
  author={Henninger, Felix and Shevchenko, Yury and Mertens, Ulf K and Kieslich, Pascal J and Hilbig, Benjamin E},
  journal={Behavior Research Methods},
  pages={1--18},
  year={2021},
  publisher={Springer}
}
@article{henrich2010weirdest,
  title={The weirdest people in the world?},
  author={Henrich, Joseph and Heine, Steven J and Norenzayan, Ara},
  journal={Behavioral and brain sciences},
  volume={33},
  number={2-3},
  pages={61--83},
  year={2010},
  publisher={Cambridge University Press}
}
@article{james2023language,
  title={Language Experience Predicts Eye Movements During Online Auditory Comprehension},
  author={James, Ariel N and Minnihan, Colleen J and Watson, Duane G},
  journal={Journal of Cognition},
  volume={6},
  number={1},
  year={2023},
  publisher={Ubiquity Press}
}
@Article{johanssonLookHereEye2014,
  title = {Look {{Here}}, {{Eye Movements Play}} a {{Functional Role}} in {{Memory Retrieval}}},
  author = {Roger Johansson and Mikael Johansson},
  date = {2014-01-01},
  journaltitle = {Psychological Science},
  shortjournal = {Psychol Sci},
  volume = {25},
  pages = {236--242},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1177/0956797613498260},
  abstract = {Research on episodic memory has established that spontaneous eye movements occur to spaces associated with retrieved information even if those spaces are blank at the time of retrieval. Although it has been claimed that such looks to “nothing” can function as facilitatory retrieval cues, there is currently no conclusive evidence for such an effect. In the present study, we addressed this fundamental issue using four direct eye manipulations in the retrieval phase of an episodic memory task: (a) free viewing on a blank screen, (b) maintaining central fixation, (c) looking inside a square congruent with the location of the to-be-recalled objects, and (d) looking inside a square incongruent with the location of the to-be-recalled objects. Our results provide novel evidence of an active and facilitatory role of gaze position during memory retrieval and demonstrate that memory for the spatial relationship between objects is more readily affected than memory for intrinsic object features.},
  file = {/Users/rachelryskin/Zotero/storage/HIYWBNM7/Johansson and Johansson - 2014 - Look Here, Eye Movements Play a Functional Role in.pdf},
  keywords = {eye-tracking,memory},
  langid = {english},
  number = {1},
}

@article{krajbich2010visual,
  title={Visual fixations and the computation and comparison of value in simple choice},
  author={Krajbich, Ian and Armel, Carrie and Rangel, Antonio},
  journal={Nature neuroscience},
  volume={13},
  number={10},
  pages={1292--1298},
  year={2010},
  publisher={Nature Publishing Group US New York}
}
@article{kukona2014lexical,
  title={Lexical interference effects in sentence processing: evidence from the visual world paradigm and self-organizing models.},
  author={Kukona, Anuenue and Cho, Pyeong Whan and Magnuson, James S and Tabor, Whitney},
  journal={Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume={40},
  number={2},
  pages={326},
  year={2014},
  publisher={American Psychological Association}
}
@article{mannsVisualPairedcomparisonTask2000,
  title = {The Visual Paired-Comparison Task as a Measure of Declarative Memory},
  author = {Joseph R. Manns and Craig E. L. Stark and Larry R. Squire},
  date = {2000-10-24},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {97},
  pages = {12375--12379},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.220398097},
  abstract = {Performance on the visual paired-comparison task depends on the integrity of the hippocampal formation in humans, monkeys, and, for an analogous task, in rats. The present study sought additional evidence in healthy volunteers concerning the nature of this task. We found that performance on the visual paired-comparison task was predictive of subsequent recognition memory performance whereas perceptual priming was unrelated to subsequent recognition memory performance. The results are consistent with the data from lesions and suggest that performance on the visual paired-comparison task measures a form of declarative memory.},
  eprint = {11027310},
  eprinttype = {pmid},
  file = {/Users/rachelryskin/Zotero/storage/QWYMGEEM/Manns et al. - 2000 - The visual paired-comparison task as a measure of .pdf;/Users/rachelryskin/Zotero/storage/86GIKB4W/12375.html},
  langid = {english},
  number = {22},
}
@article{de2016psychophysics,
  title={Psychophysics in a Web browser? Comparing response times collected with JavaScript and Psychophysics Toolbox in a visual search task},
  author={De Leeuw, Joshua R and Motz, Benjamin A},
  journal={Behavior Research Methods},
  volume={48},
  pages={1--12},
  year={2016},
  publisher={Springer}
}
@article{passell2021cognitive,
  title={Cognitive test scores vary with choice of personal digital device},
  author={Passell, Eliza and Strong, Roger W and Rutter, Lauren A and Kim, Heesu and Scheuer, Luke and Martini, Paolo and Grinspoon, Liz and Germine, Laura},
  journal={Behavior Research Methods},
  volume={53},
  number={6},
  pages={2544--2557},
  year={2021},
  publisher={Springer}
}
@InProceedings{papoutsaki2016webgazer,
  title = {{{WebGazer}}: {{Scalable}} Webcam Eye Tracking Using User Interactions},
  booktitle = {Proceedings of the 25th International Joint Conference on Artificial Intelligence ({{IJCAI}})},
  author = {Alexandra Papoutsaki and Patsorn Sangkloy and James Laskey and Nediyana Daskalova and Jeff Huang and James Hays},
  date = {2016},
  pages = {3839--3845},
  organization = {{AAAI}},
}

@article{prystauka2023online,
  title={Online eye tracking and real-time sentence processing: On opportunities and efficacy for capturing psycholinguistic effects of different magnitudes and diversity},
  author={Prystauka, Yanina and Altmann, Gerry TM and Rothman, Jason},
  journal={Behavior Research Methods},
  pages={1--19},
  year={2023},
  publisher={Springer}
}

@Manual{R-afex,
  title = {afex: Analysis of Factorial Experiments},
  author = {Henrik Singmann and Ben Bolker and Jake Westfall and Frederik Aust and Mattan S. Ben-Shachar},
  year = {2021},
  note = {R package version 0.28-1},
  url = {https://CRAN.R-project.org/package=afex},
}
@Manual{R-base,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2021},
  url = {https://www.R-project.org/},
}
@Manual{R-broom.mixed,
  title = {broom.mixed: Tidying Methods for Mixed Models},
  author = {Ben Bolker and David Robinson},
  year = {2020},
  note = {R package version 0.2.6},
  url = {https://CRAN.R-project.org/package=broom.mixed},
}
@Manual{R-dplyr,
  title = {dplyr: A Grammar of Data Manipulation},
  author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller},
  year = {2021},
  note = {R package version 1.0.7},
  url = {https://CRAN.R-project.org/package=dplyr},
}
@Manual{R-forcats,
  title = {forcats: Tools for Working with Categorical Variables (Factors)},
  author = {Hadley Wickham},
  year = {2021},
  note = {R package version 0.5.1},
  url = {https://CRAN.R-project.org/package=forcats},
}
@Book{R-ggplot2,
  author = {Hadley Wickham},
  title = {ggplot2: Elegant Graphics for Data Analysis},
  publisher = {Springer-Verlag New York},
  year = {2016},
  isbn = {978-3-319-24277-4},
  url = {https://ggplot2.tidyverse.org},
}
@Article{R-jsonlite,
  title = {The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R Objects},
  author = {Jeroen Ooms},
  journal = {arXiv:1403.2805 [stat.CO]},
  year = {2014},
  url = {https://arxiv.org/abs/1403.2805},
}
@Article{R-lme4,
  title = {Fitting Linear Mixed-Effects Models Using {lme4}},
  author = {Douglas Bates and Martin M{\"a}chler and Ben Bolker and Steve Walker},
  journal = {Journal of Statistical Software},
  year = {2015},
  volume = {67},
  number = {1},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
}
@Article{R-lmerTest,
  title = {{lmerTest} Package: Tests in Linear Mixed Effects Models},
  author = {Alexandra Kuznetsova and Per B. Brockhoff and Rune H. B. Christensen},
  journal = {Journal of Statistical Software},
  year = {2017},
  volume = {82},
  number = {13},
  pages = {1--26},
  doi = {10.18637/jss.v082.i13},
}
@Manual{R-Matrix,
  title = {Matrix: Sparse and Dense Matrix Classes and Methods},
  author = {Douglas Bates and Martin Maechler},
  year = {2021},
  note = {R package version 1.3-3},
  url = {https://CRAN.R-project.org/package=Matrix},
}
@Manual{R-papaja,
  author = {Frederik Aust and Marius Barth},
  title = {{papaja}: {Create} {APA} manuscripts with {R Markdown}},
  year = {2020},
  note = {R package version 0.1.0.9997},
  url = {https://github.com/crsh/papaja},
}
@Manual{R-readr,
  title = {readr: Read Rectangular Text Data},
  author = {Hadley Wickham and Jim Hester},
  year = {2020},
  note = {R package version 1.4.0},
  url = {https://CRAN.R-project.org/package=readr},
}
@Manual{R-stringr,
  title = {stringr: Simple, Consistent Wrappers for Common String Operations},
  author = {Hadley Wickham},
  year = {2019},
  note = {R package version 1.4.0},
  url = {https://CRAN.R-project.org/package=stringr},
}
@Manual{R-tidyr,
  title = {tidyr: Tidy Messy Data},
  author = {Hadley Wickham},
  year = {2021},
  note = {R package version 1.1.3},
  url = {https://CRAN.R-project.org/package=tidyr},
}

@Manual{R-shiny,
  title = {shiny: Web Application Framework for R},
  author = {Winston Chang and Joe Cheng and JJ Allaire and Carson Sievert and Barret Schloerke and Yihui Xie and Jeff Allen and Jonathan McPherson and Alan Dipert and Barbara Borges},
  year = {2021},
  note = {R package version 1.6.0},
  url = {https://CRAN.R-project.org/package=shiny},
}

@Manual{R-tinylabels,
  title = {{tinylabels}: Lightweight Variable Labels},
  author = {Marius Barth},
  year = {2022},
  note = {R package version 0.2.3},
  url = {https://cran.r-project.org/package=tinylabels},
}

@article{rayner1998eye,
  title={Eye movements in reading and information processing: 20 years of research.},
  author={Rayner, Keith},
  journal={Psychological bulletin},
  volume={124},
  number={3},
  pages={372},
  year={1998},
  publisher={American Psychological Association}
}
@incollection{richardsonEyeTrackingResearch2004,
	address = {New York},
	title = {Eye tracking: {Research} areas and applications.},
	volume = {572},
	date = 2004,
	booktitle = {Encyclopedia of biomaterials and biomedical engineering},
	publisher = {Marcel Dekker},
	author = {Richardson, Daniel C. and Spivey, Michael J.},
	editor = {Wnek, G. and Bowlin, G.},
}
@article{ryskin2023real,
  title={Real-time inference in communication across cultures: Evidence from a nonindustrialized society.},
  author={Ryskin, Rachel and Salinas, Miguel and Piantadosi, Steven and Gibson, Edward},
  journal={Journal of Experimental Psychology: General},
  volume={152},
  number={5},
  pages={1245},
  year={2023},
  publisher={American Psychological Association}
}
@Article{ryskinVerbBiasesAre2017,
  title = {Verb Biases Are Shaped through Lifelong Learning.},
  author = {Rachel Ryskin and Zhenghan Qi and Melissa C. Duff and Sarah Brown-Schmidt},
  date = {2017-05},
  journaltitle = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {43},
  pages = {781--794},
  issn = {1939-1285, 0278-7393},
  doi = {10.1037/xlm0000341},
  abstract = {Verbs often participate in more than 1 syntactic structure, but individual verbs can be biased in terms of whether they are used more often with 1 structure or the other. For instance, in a sentence such as “Bop the bunny with the flower,” the phrase “with the flower” is more likely to indicate an instrument with which to “bop,” rather than which “bunny” to bop. Conversely, in a sentence such as “Choose the cow with the flower,” the phrase “with the flower” is more likely to indicate which “cow” to choose. An open question is where these biases come from and whether they continue to be shaped in adulthood in a way that has lasting consequences for real-time processing of language. In Experiment 1 we replicated previous findings that these language-wide biases guide online syntactic processing in a computer-based visual-world paradigm. In Experiment 2, we tested the malleability of these biases by exposing adults to initially unbiased verbs situated in unambiguous contexts that led to either instrument or modifier interpretations. During test, participants interpreted sentences containing either modifier- or instrument-trained verbs in ambiguous contexts. Eyemovement and action data show that participants’ considerations of the candidate interpretations of the ambiguous with-phrases were guided by the newly learned verb biases. These results suggest that co-occurrence information about specific verbs and syntactic structures embedded in language experiences plays a role in forming, and continuously shaping, the verb biases that constitute a part of the broader representation of the language.},
  langid = {english},
  number = {5},
}

@article{semmelmann2018online,
  title={Online webcam-based eye tracking in cognitive science: A first look},
  author={Semmelmann, Kilian and Weigelt, Sarah},
  journal={Behavior Research Methods},
  volume={50},
  pages={451--465},
  year={2018},
  publisher={Springer}
}

@Article{shimojoGazeBiasBoth2003,
  title = {Gaze Bias Both Reflects and Influences Preference},
  author = {Shinsuke Shimojo and Claudiu Simion and Eiko Shimojo and Christian Scheier},
  date = {2003-12},
  journaltitle = {Nature Neuroscience},
  shortjournal = {Nat Neurosci},
  volume = {6},
  pages = {1317--1322},
  issn = {1097-6256, 1546-1726},
  doi = {10.1038/nn1150},
  file = {/Users/rachelryskin/Zotero/storage/HCUL243S/Shimojo et al. - 2003 - Gaze bias both reflects and influences preference.pdf},
  langid = {english},
  number = {12},
}

@Article{snedekerDevelopingConstraintsParsing2004a,
  title = {The Developing Constraints on Parsing Decisions: {{The}} Role of Lexical-Biases and Referential Scenes in Child and Adult Sentence Processing},
  shorttitle = {The Developing Constraints on Parsing Decisions},
  author = {Jesse Snedeker and John C. Trueswell},
  date = {2004-11},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {49},
  pages = {238--299},
  issn = {00100285},
  doi = {10.1016/j.cogpsych.2004.03.001},
  langid = {english},
  number = {3},
}

@article{simonsohn2015,
author = {Uri Simonsohn},
title ={Small Telescopes: Detectability and the Evaluation of Replication Results},
journal = {Psychological Science},
volume = {26},
number = {5},
pages = {559-569},
year = {2015},
doi = {10.1177/0956797614567341},
    note ={PMID: 25800521},

URL = { 
        https://doi.org/10.1177/0956797614567341
    
},
eprint = { 
        https://doi.org/10.1177/0956797614567341
    
}
,
    abstract = { This article introduces a new approach for evaluating replication results. It combines effect-size estimation with hypothesis testing, assessing the extent to which the replication results are consistent with an effect size big enough to have been detectable in the original study. The approach is demonstrated by examining replications of three well-known findings. Its benefits include the following: (a) differentiating “unsuccessful” replication attempts (i.e., studies yielding p > .05) that are too noisy from those that actively indicate the effect is undetectably different from zero, (b) “protecting” true findings from underpowered replications, and (c) arriving at intuitively compelling inferences in general and for the revisited replications in particular. }
}

@article{slim2022moving,
  title={Moving visual world experiments online? A web-based replication of Dijkgraaf, Hartsuiker, and Duyck (2017) using PCIbex and WebGazer. js},
  author={Slim, Mieke Sarah and Hartsuiker, Robert J},
  journal={Behavior Research Methods},
  pages={1--19},
  year={2022},
  publisher={Springer}
}

@Article{spiveyOculomotorMechanismsActivated2001,
  title = {Oculomotor Mechanisms Activated by Imagery and Memory: Eye Movements to Absent Objects},
  shorttitle = {Oculomotor Mechanisms Activated by Imagery and Memory},
  author = {Michael J. Spivey and Joy J. Geng},
  date = {2001-11-01},
  journaltitle = {Psychological Research},
  shortjournal = {Psychological Research Psychologische Forschung},
  volume = {65},
  pages = {235--241},
  issn = {1430-2772},
  doi = {10.1007/s004260100059},
  abstract = {It is hypothesized that eye movements are used to coordinate elements of a mental model with elements of the visual field. In two experiments, eye movements were recorded while observers imagined or recalled objects that were not present in the visual display. In both cases, observers spontaneously looked at particular blank regions of space in a systematic fashion, to manipulate and organize spatial relationships between mental and/or retinal images. These results contribute to evidence that interpreting a linguistic description of a visual scene requires a spatial (mental model) representation, and they support claims regarding the allocation of position markers in visual space for the manipulation of visual attention. More broadly, our results point to a concrete embodiment of cognition, in that a construction of a mental image is almost “acted out” by the eye movements, and a mental search of internal memory is accompanied by an ocolumotor search of external space.},
  file = {/Users/rachelryskin/Zotero/storage/4W3IHLCY/Spivey and Geng - 2001 - Oculomotor mechanisms activated by imagery and mem.pdf},
  keywords = {eye-tracking,memory},
  langid = {english},
  number = {4},
}

@article{sun2020another,
  title={Another look at the online processing of scalar inferences: An investigation of conflicting findings from visual-world eye-tracking studies},
  author={Sun, Chao and Breheny, Richard},
  journal={Language, Cognition and Neuroscience},
  volume={35},
  number={8},
  pages={949--979},
  year={2020},
  publisher={Taylor \& Francis}
}
@Article{tanenhaus1995,
  ids = {tanenhausIntegrationVisualLinguistic1995,tanenhausTanenhaus1995Science},
  title = {Integration of Visual and Linguistic Information in Spoken Language Comprehension},
  author = {Michael K Tanenhaus and Michael J Spivey-Knowlton and Kathleen M Eberhard and Julie C Sedivy},
  date = {1995},
  journaltitle = {Science},
  volume = {268},
  pages = {1632--1634},
  publisher = {{American Association for the Advancement of Science}},
  eprint = {7777863},
  eprinttype = {pmid},
  file = {/Users/rachelryskin/Zotero/storage/JW6UJ6PQ/Tanenhaus(1995)Science.pdf;/Users/rachelryskin/Zotero/storage/LN97T6RB/1632.html},
  number = {5217},
}
@article{van2023validation,
  title={The validation of online webcam-based eye-tracking: The replication of the cascade effect, the novelty preference, and the visual world paradigm},
  author={Van der Cruyssen, Ine and Ben-Shakhar, Gershon and Pertzov, Yoni and Guy, Nitzan and Cabooter, Quinn and Gunschera, Lukas J and Verschuere, Bruno},
  journal={Behavior Research Methods},
  pages={1--14},
  year={2023},
  publisher={Springer}
}
@article{vos2022comparing,
  title={Comparing infrared and webcam eye tracking in the Visual World Paradigm},
  author={Vos, Myrte and Minor, Serge and Ramchand, Gillian C},
  year={2022},
  journal = {Glossa Psycholinguistics},
  volume = {1},
  publisher={University of California Press}
}
@article{yang2021webcam,
  title={Webcam-based online eye-tracking for behavioral research},
  author={Yang, Xiaozhi and Krajbich, Ian},
  journal={Judgment and Decision Making},
  volume={16},
  number={6},
  pages={1486},
  year={2021},
  publisher={Society for Judgment \& Decision Making}
}

@book{yarbus1967eye,
  title={Eye movements and Vision},
  author={Yarbus, Alfred L},
  year={1967},
  place={New York},
  publisher={Plenum Press}
}

@misc{zehr2018PCIbex,
  title ={ PennController for Internet Based Experiments (IBEX)},
  author={Zehr, J., and Schwarz, F.},
  year = {2018},
  url = {https://doi.org/10.17605/OSF.IO/MD832}
}

@article{steffan2024validation,
  title={Validation of an open source, remote web-based eye-tracking method (WebGazer) for research in early childhood},
  author={Steffan, Adrian and Zimmer, Lucie and Arias-Trejo, Natalia and Bohn, Manuel and Dal Ben, Rodrigo and Flores-Coronado, Marco A and Franchin, Laura and Garbisch, Isa and Grosse Wiesmann, Charlotte and Hamlin, J Kiley and others},
  journal={Infancy},
  volume={29},
  number={1},
  pages={31--55},
  year={2024},
  publisher={Wiley Online Library}
}

@article{hagihara2024exploration,
  title={Exploration of factors affecting webcam-based automated gaze coding},
  author={Hagihara, Hiromichi and Zaadnoordijk, Lorijn and Cusack, Rhodri and Kimura, Nanako and Tsuji, Sho},
  journal={Behavior Research Methods},
  pages={1--17},
  year={2024},
  publisher={Springer}
}

@article{james2023language,
  title={Language experience predicts eye movements during online auditory comprehension},
  author={James, Ariel N and Minnihan, Colleen J and Watson, Duane G},
  journal={Journal of Cognition},
  volume={6},
  number={1},
  year={2023},
  publisher={Ubiquity Press}
}

@article{konkle2010conceptual,
  title={Conceptual distinctiveness supports detailed visual long-term memory for real-world objects.},
  author={Konkle, Talia and Brady, Timothy F and Alvarez, George A and Oliva, Aude},
  journal={Journal of experimental Psychology: general},
  volume={139},
  number={3},
  pages={558},
  year={2010},
  publisher={American Psychological Association}
}